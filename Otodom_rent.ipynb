{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc422aa",
   "metadata": {},
   "source": [
    "# Web scraping Otodom (rent)\n",
    "The program that collects data from the Otodom website (https://www.otodom.pl/) and saves in a csv file and access to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149acb4a-5ec7-44bf-b9b9-a97d3b7d9c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (5.1.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: geopy in /opt/conda/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /opt/conda/lib/python3.9/site-packages (from geopy) (1.52)\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.9/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.9/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: sqlalchemy==1.3.9 in /opt/conda/lib/python3.9/site-packages (1.3.9)\n",
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (1.3.9)\n",
      "Requirement already satisfied: ipython>=1.0 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (7.23.1)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: prettytable<1 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (0.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.0.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (49.6.0.post20210108)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (2.9.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (3.0.18)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.9/site-packages (2.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install plotly\n",
    "!pip install numpy\n",
    "!pip install geopy\n",
    "!pip install html5lib\n",
    "!pip install sqlalchemy==1.3.9\n",
    "!pip install ipython-sql\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbcc26d-6170-4f9c-af03-bab6917d2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import clear_output\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import Nominatim\n",
    "import html5lib\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dced3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca93b75-4fb8-4f76-bcf3-4befb72f101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = Nominatim(user_agent=\"myGeocoder\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b13e40",
   "metadata": {},
   "source": [
    "## Creating a function that takes data from a page and cleans it so that fans can no longer have the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c917c35-514e-4fc8-b673-26e031c44579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(link):\n",
    "    try:\n",
    "        html_data = requests.get(link)\n",
    "        html_data.content\n",
    "        soup = BeautifulSoup(html_data.content, 'html5lib')\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        rent_price = soup.find('strong',attrs={\"data-cy\":\"adPageHeaderPrice\"}).text\n",
    "        rent_price = rent_price.replace(\"zł\",\"\").replace(\" \",\"\").replace(\",\", \".\")\n",
    "        rent_price = float(rent_price)\n",
    "    except Exception:\n",
    "        rent_price = np.NaN\n",
    "\n",
    "    try:\n",
    "        m2 = soup.find('div',attrs={\"aria-label\":\"Powierzchnia\"}).find_all('div')[1].text\n",
    "        m2 = m2.replace(\"m²\",\"\").replace(\",\",\".\")\n",
    "        m2 = float(m2)\n",
    "    except Exception:\n",
    "        m2 = np.NaN\n",
    "     \n",
    "    try:\n",
    "        Deposit = soup.find('div',attrs={\"aria-label\":\"Kaucja\"}).find_all('div')[1].text\n",
    "        Deposit = Deposit.replace(\"zł\",\"\").replace(\" \",\"\").replace(\",\", \".\")\n",
    "        Deposit = float(Deposit)\n",
    "    except Exception:\n",
    "        Deposit = np.NaN\n",
    "\n",
    "    try:\n",
    "        Type_of_building = soup.find('div',attrs={\"aria-label\":\"Rodzaj zabudowy\"}).find_all('div')[1].text\n",
    "        str(Type_of_building)\n",
    "    except Exception:\n",
    "        Type_of_building = np.NaN\n",
    "\n",
    "    try:\n",
    "        room_number = soup.find('div',attrs={\"aria-label\":\"Liczba pokoi\"}).find_all('div')[1].text\n",
    "        room_number = room_number.replace(\",\", \".\")\n",
    "        room_number = float(room_number)\n",
    "    except Exception:\n",
    "        room_number = np.NaN\n",
    "\n",
    "    try:\n",
    "        Building_material = soup.find('div',attrs={\"aria-label\":\"Materiał budynku\"}).find_all('div')[1].text\n",
    "        Building_material = str(Building_material)\n",
    "    except Exception:\n",
    "        Building_material = np.NaN\n",
    "        \n",
    "    try:\n",
    "        Year_of_construction = soup.find('div',attrs={\"aria-label\":\"Rok budowy\"}).find_all('div')[1].text\n",
    "        Year_of_construction = Year_of_construction.replace(\",\", \".\")\n",
    "        Year_of_construction = float(Year_of_construction)\n",
    "    except Exception:\n",
    "        Year_of_construction = np.NaN\n",
    "    \n",
    "    try:\n",
    "        floor = soup.find('div',attrs={\"aria-label\":\"Piętro\"}).find_all('div')[1].text\n",
    "        floor = floor.replace(\",\", \".\")\n",
    "        floor = float(floor)\n",
    "    except Exception:\n",
    "        floor = np.NaN\n",
    "        \n",
    "    try:\n",
    "        windows = soup.find('div',attrs={\"aria-label\":\"Okna\"}).find_all('div')[1].text\n",
    "        windows = str(windows)\n",
    "    except Exception:\n",
    "        windows = np.NaN\n",
    "    \n",
    "    try:\n",
    "        Number_of_floors = soup.find('div',attrs={\"aria-label\":\"Liczba pięter\"}).find_all('div')[1].text\n",
    "        Number_of_floors = Number_of_floors.replace(\",\", \".\")\n",
    "        Number_of_floors = float(Number_of_floors)\n",
    "    except Exception:\n",
    "        Number_of_floors = np.NaN\n",
    "        \n",
    "    try:\n",
    "        Heating = soup.find('div',attrs={\"aria-label\":\"Ogrzewanie\"}).find_all('div')[1].text\n",
    "        Heating = str(Heating)\n",
    "    except Exception:\n",
    "        Heating = np.NaN\n",
    "\n",
    "    media = np.NaN\n",
    "    tab_all = soup.find('div',attrs={\"class\":\"css-1lw3ul3 ex3yvbv4\"})\n",
    "    try:\n",
    "        for two in tab_all.find_all('div'):\n",
    "            tab_all_deep = two.find_all('h3')[0].text\n",
    "            if tab_all_deep == \"media\":\n",
    "                tab_all_deep_2 = two.find_all('ul')[0]\n",
    "                media = \"\"\n",
    "                for one in tab_all_deep_2.find_all('li'):\n",
    "                    media += one.text + \", \"\n",
    "                media = media[:-2]\n",
    "    except:\n",
    "        pass\n",
    "     \n",
    "    security = np.NaN\n",
    "    tab_all = soup.find('div',attrs={\"class\":\"css-1lw3ul3 ex3yvbv4\"})\n",
    "    try:\n",
    "        for two in tab_all.find_all('div'):\n",
    "            tab_all_deep = two.find_all('h3')[0].text\n",
    "            if tab_all_deep == \"zabezpieczenia\":\n",
    "                tab_all_deep_2 = two.find_all('ul')[0]\n",
    "                security = \"\"\n",
    "                for one in tab_all_deep_2.find_all('li'):\n",
    "                    security += one.text + \", \"\n",
    "                security = security[:-2]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        \n",
    "    Additional_information = np.NaN\n",
    "    tab_all = soup.find('div',attrs={\"class\":\"css-1lw3ul3 ex3yvbv4\"})\n",
    "    try:\n",
    "        for two in tab_all.find_all('div'):\n",
    "            tab_all_deep = two.find_all('h3')[0].text\n",
    "            if tab_all_deep == \"informacje dodatkowe\":\n",
    "                tab_all_deep_2 = two.find_all('ul')[0]\n",
    "                Additional_information = \"\"\n",
    "                for one in tab_all_deep_2.find_all('li'):\n",
    "                    Additional_information += one.text + \", \"\n",
    "                Additional_information = Additional_information[:-2]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "         \n",
    "    Equipment = np.NaN\n",
    "    tab_all = soup.find('div',attrs={\"class\":\"css-1lw3ul3 ex3yvbv4\"})\n",
    "    try:\n",
    "        for two in tab_all.find_all('div'):\n",
    "            tab_all_deep = two.find_all('h3')[0].text\n",
    "            if tab_all_deep == \"wyposażenie\":\n",
    "                tab_all_deep_2 = two.find_all('ul')[0]\n",
    "                Equipment = \"\"\n",
    "                for one in tab_all_deep_2.find_all('li'):\n",
    "                    Equipment += one.text + \", \"\n",
    "                Equipment = Equipment[:-2]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        link_2 = link\n",
    "        link_2 = str(link_2)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        location = soup.find('a',attrs={\"class\":\"css-1ibwe9h e1nbpvi62\"}).text\n",
    "    except Exception:\n",
    "        location = np.NaN\n",
    "        \n",
    "    # Generate latitude and longitude using location\n",
    "    \n",
    "    try:\n",
    "        location = locator.geocode(location)\n",
    "        geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "        latitude = location.latitude\n",
    "        longitude = location.longitude\n",
    "    except Exception:\n",
    "        latitude = np.NaN\n",
    "        longitude = np.NaN\n",
    "    \n",
    "\n",
    "        \n",
    "    return {'rent_price': rent_price, 'm2': m2,'Deposit': Deposit, 'Type_of_building': Type_of_building,\n",
    "           'room_number':room_number,'Building_material': Building_material, 'Year_of_construction': Year_of_construction,\n",
    "            'floor': floor, 'windows': windows,\n",
    "           'Number_of_floors': Number_of_floors, 'Heating': Heating,\n",
    "            'media': media,'link_2': link_2, 'security': security, 'Additional_information': Additional_information,\n",
    "            'Equipment': Equipment, 'location': location, 'latitude': latitude, 'longitude': longitude}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d084fe",
   "metadata": {},
   "source": [
    "## Creating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51f9c10-cc78-478c-a55e-ddd2d11ec132",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'rent_price': [], 'm2': [],'Deposit': [], 'Type_of_building': [],\n",
    "        'room_number': [],'Building_material': [], 'Year_of_construction': [],\n",
    "        'floor': [], 'windows': [],\n",
    "         'Number_of_floors': [], 'Heating': [], 'media': [], 'security': [], 'link_2': [],\n",
    "         'Additional_information': [], 'Equipment': [], 'location': [], 'latitude': [], 'longitude': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c119be",
   "metadata": {},
   "source": [
    "## Replace the table in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44e078a-73f9-40ce-82bb-1291068bbdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [rent_price, m2, Deposit, Type_of_building, room_number, Building_material, Year_of_construction, floor, windows, Number_of_floors, Heating, media, security, link_2, Additional_information, Equipment, location, latitude, longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_table = pd.DataFrame(table)\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169bf01",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "The main loop where apartments for rent from Warsaw are selected.\n",
    "\n",
    "First, the first page with apartments is opened and then the loop looks through all the mixed areas of this page and retrieves key information from themThen it goes to the next page.\n",
    "Depending on the settings, we will help you browse a defined number of pages or all.\n",
    "\n",
    "If we want to view all pages we use \"while\" and if a specific number of pages we enter it in \"range\" in the first \"for\" pentle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ef3d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read_announcements  7731\n",
      "Link_ERROR  0\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "Link_ERROR = 0\n",
    "Read_announcements = 0\n",
    "page = 1\n",
    "while True:\n",
    "    \n",
    "# for page in range(1,10):  \n",
    "    try:\n",
    "        html_data_link = requests.get(f\"https://www.otodom.pl/pl/oferty/wynajem/mieszkanie/warszawa?page={page}\")\n",
    "        page += 1\n",
    "    except Exception:\n",
    "        print(\"Link_ERROR\")\n",
    "        continue\n",
    "    \n",
    "    soup_link = BeautifulSoup(html_data_link.content, 'html5lib')\n",
    "    \n",
    "    if soup_link.find('div',attrs={\"class\":\"css-pi2gf8 e1qwpsp45\"}) is None:\n",
    "        pass\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    for offer in soup_link.find_all('a',attrs={\"data-cy\":\"listing-item-link\"}):\n",
    "            new_row = get_data(\"https://www.otodom.pl\"+ offer['href'])\n",
    "            \n",
    "            \n",
    "            if new_row == None:\n",
    "                Link_ERROR += 1\n",
    "            else:\n",
    "                df_table = df_table.append(new_row, ignore_index=True)\n",
    "                Read_announcements += 1\n",
    "                clear_output(wait=True)\n",
    "                print(\"Read_announcements \", Read_announcements)\n",
    "                print(\"Link_ERROR \",Link_ERROR)     \n",
    "                \n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24dba6",
   "metadata": {},
   "source": [
    "## We choose the name of the table and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2123a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'Warsaw_rent_full'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d640c7b",
   "metadata": {},
   "source": [
    "## Serving to the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d49b9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table.to_csv (table_name +'.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9b721",
   "metadata": {},
   "source": [
    "## Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c756f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psql = psycopg2.connect(host='192.168.10.163', port='5432', database='Otodom', user='barto', password='biznes')\n",
    "cur = psql.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e32c7",
   "metadata": {},
   "source": [
    "## Creating a table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DROP TABLE IF EXISTS '+ table_name)\n",
    "createTableCommand = 'CREATE TABLE ' + table_name + '''(ID int NOT NULL,\n",
    "    rent_price float,\n",
    "    m2 float,\n",
    "    Deposit float,\n",
    "    Type_of_building VARCHAR,\n",
    "    room_number float,\n",
    "    Building_material VARCHAR,\n",
    "    Year_of_construction float,\n",
    "    floor float,\n",
    "    windows VARCHAR,\n",
    "    Number_of_floors float,\n",
    "    Heating VARCHAR,\n",
    "    media VARCHAR,\n",
    "    security VARCHAR,\n",
    "    link_2 VARCHAR,\n",
    "    Additional_information VARCHAR,\n",
    "    Equipment VARCHAR,\n",
    "    location VARCHAR,\n",
    "    latitude float,\n",
    "    longitude float,\n",
    "    PRIMARY KEY (ID)\n",
    "    )'''\n",
    "cur.execute(createTableCommand)\n",
    "psql.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43daeb5c",
   "metadata": {},
   "source": [
    "## Loading data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63091fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "insert_table = ['ID',\n",
    "    'rent_price',\n",
    "    'm2',\n",
    "    'Deposit',\n",
    "    'Type_of_building',\n",
    "    'room_number',\n",
    "    'Building_material',\n",
    "    'Year_of_construction',\n",
    "    'floor',\n",
    "    'windows',\n",
    "    'Number_of_floors',\n",
    "    'Heating',\n",
    "    'media',\n",
    "    'security',\n",
    "    'link_2',\n",
    "    'Additional_information',\n",
    "    'Equipment',\n",
    "    'location',\n",
    "    'latitude',\n",
    "    'longitude']\n",
    "\n",
    "\n",
    "a = 0\n",
    "for row in df_table.itertuples():\n",
    "    full=\"\"\n",
    "    full_fit=\"INSERT INTO \" + table_name + \"(\"\n",
    "    for (column, insert) in zip(row, insert_table):\n",
    "        if str(column) =='nan':\n",
    "            continue\n",
    "        column = str(column)\n",
    "        column = column.replace(\"'\", \"''\")\n",
    "        full +=\"'\"+column+\"'\"+\", \"\n",
    "        full_fit += insert + ', '  \n",
    "        \n",
    "    full=full[:-2]\n",
    "    full_fit=full_fit[:-2]\n",
    "    full_fit=full_fit+')'\n",
    "    Value_data='VALUES ('+full+');'\n",
    "    insertDataCommand = full_fit+\"\\r\\n\"+Value_data\n",
    "    cur.execute(insertDataCommand)\n",
    "psql.commit()\n",
    "print(\"Finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
